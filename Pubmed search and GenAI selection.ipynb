{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas metapub tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ['NCBI_API_KEY'] = 'your_ncbi_api_key'\n",
    "from functools import reduce\n",
    "from metapub import PubMedFetcher\n",
    "fetch = PubMedFetcher()\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from xml.etree.ElementTree import ParseError\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"(((delirium) AND ((detection) OR (prediction))) AND (ICU)) OR (((delirium) AND ((detection) OR (prediction))) AND (intensive care unit))\"\n",
    "num_of_articles = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, fetch the PMIDs\n",
    "logger.info(\"Fetching PMIDs from PubMed...\")\n",
    "try:\n",
    "    pmids = fetch.pmids_for_query(keyword, retmax=num_of_articles)\n",
    "    logger.info(f\"Retrieved {len(pmids)} PMIDs\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error fetching PMIDs: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve information for each article with error handling\n",
    "articles = {}\n",
    "failed_pmids = []\n",
    "\n",
    "for pmid in tqdm(pmids, desc=\"Retrieving articles\"):\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            articles[pmid] = fetch.article_by_pmid(pmid)\n",
    "            break  # Success, break the retry loop\n",
    "        except ParseError as e:\n",
    "            logger.warning(f\"XML parsing error for PMID {pmid} on attempt {attempt + 1}: {str(e)}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                logger.error(f\"Failed to retrieve article for PMID {pmid} after {max_retries} attempts\")\n",
    "                failed_pmids.append(pmid)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error retrieving article for PMID {pmid} on attempt {attempt + 1}: {str(e)}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                logger.error(f\"Failed to retrieve article for PMID {pmid} after {max_retries} attempts\")\n",
    "                failed_pmids.append(pmid)\n",
    "        \n",
    "        time.sleep(2 ** attempt)  # Exponential backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log summary\n",
    "logger.info(f\"Successfully retrieved {len(articles)} articles\")\n",
    "logger.info(f\"Failed to retrieve {len(failed_pmids)} articles\")\n",
    "\n",
    "if failed_pmids:\n",
    "    logger.info(\"Failed PMIDs: \" + \", \".join(map(str, failed_pmids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get(article, attr):\n",
    "    try:\n",
    "        value = getattr(article, attr)\n",
    "        if attr == 'citation':\n",
    "            if getattr(article, 'book_accession_id', None):\n",
    "                return generate_book_citation(article)\n",
    "            elif callable(value):\n",
    "                return value()\n",
    "        elif attr == 'doi':  # Add special handling for DOI\n",
    "            if callable(value):\n",
    "                doi = value()\n",
    "                return doi.lower() if doi else None  # Normalize DOI to lowercase\n",
    "        elif callable(value):\n",
    "            return value()\n",
    "        return value\n",
    "    except (AttributeError, IndexError):\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_book_citation(book):\n",
    "    try:\n",
    "        title = book.title or \"Untitled\"\n",
    "        authors = \", \".join(book.authors) if book.authors else \"Unknown Author\"\n",
    "        year = book.year or \"Unknown Year\"\n",
    "        publisher = book.publisher or \"Unknown Publisher\"\n",
    "        return f\"{authors}. {title}. {publisher}, {year}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating book citation: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_doi_link(doi):\n",
    "    \"\"\"Generate DOI link from DOI string\"\"\"\n",
    "    if doi and isinstance(doi, str):\n",
    "        return f\"https://doi.org/{doi}\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant information and create DataFrames\n",
    "titles = {}\n",
    "abstracts = {}\n",
    "authors = {}\n",
    "years = {}\n",
    "volumes = {}\n",
    "issues = {}\n",
    "journals = {}\n",
    "citations = {}\n",
    "links = {}\n",
    "dois = {}\n",
    "doi_links = {}\n",
    "\n",
    "\n",
    "for pmid in pmids:\n",
    "    article = articles[pmid]\n",
    "    titles[pmid] = safe_get(article, 'title')\n",
    "    abstracts[pmid] = safe_get(article, 'abstract')\n",
    "    authors[pmid] = ', '.join(safe_get(article, 'authors') or [])\n",
    "    years[pmid] = safe_get(article, 'year')\n",
    "    volumes[pmid] = safe_get(article, 'volume')\n",
    "    issues[pmid] = safe_get(article, 'issue')\n",
    "    journals[pmid] = safe_get(article, 'journal')\n",
    "    citations[pmid] = safe_get(article, 'citation')\n",
    "    links[pmid] = f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\"\n",
    "    dois[pmid] = safe_get(article, 'doi')\n",
    "    doi_links[pmid] = generate_doi_link(dois[pmid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual DataFrames\n",
    "Title = pd.DataFrame(list(titles.items()), columns=['pmid', 'Title'])\n",
    "Abstract = pd.DataFrame(list(abstracts.items()), columns=['pmid', 'Abstract'])\n",
    "Author = pd.DataFrame(list(authors.items()), columns=['pmid', 'Author'])\n",
    "Year = pd.DataFrame(list(years.items()), columns=['pmid', 'Year'])\n",
    "Volume = pd.DataFrame(list(volumes.items()), columns=['pmid', 'Volume'])\n",
    "Issue = pd.DataFrame(list(issues.items()), columns=['pmid', 'Issue'])\n",
    "Journal = pd.DataFrame(list(journals.items()), columns=['pmid', 'Journal'])\n",
    "Citation = pd.DataFrame(list(citations.items()), columns=['pmid', 'Citation'])\n",
    "Link = pd.DataFrame(list(links.items()), columns=['pmid', 'Link'])\n",
    "DOI = pd.DataFrame(list(dois.items()), columns=['pmid', 'DOI'])\n",
    "DOI_Link = pd.DataFrame(list(doi_links.items()), columns=['pmid', 'DOI_Link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all DataFrames into a single one\n",
    "data_frames = [Title, Abstract, Author, Year, Volume, Issue, Journal, Citation, Link, DOI, DOI_Link]\n",
    "df_merged = reduce(lambda left, right: pd.merge(left, right, on=['pmid'], how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the merged DataFrame\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_abstract_for_algorithm(abstract):\n",
    "    \"\"\"\n",
    "    Analyze abstract using Gemini API to determine if it describes a delirium prediction/detection algorithm\n",
    "    \"\"\"\n",
    "    if pd.isna(abstract):\n",
    "        return False\n",
    "        \n",
    "    genai.configure(api_key='your_google_genai_api_key')\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze this abstract and determine if it reports a delirium prediction or detection algorithm.\n",
    "    Answer only 'yes' if it describes developing or validating a prediction model, machine learning algorithm, \n",
    "    or detection system for delirium. Answer 'no' otherwise.\n",
    "    \n",
    "    Abstract: {abstract}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-pro')\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip().lower() == 'yes'\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing abstract: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable progress bar\n",
    "tqdm.pandas(desc=\"Analyzing abstracts\")\n",
    "\n",
    "print(f\"Processing {len(df_merged)} abstracts...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add algorithm analysis column\n",
    "df_merged['is_algorithm'] = df_merged['Abstract'].progress_apply(analyze_abstract_for_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for only algorithm papers\n",
    "algorithm_papers = df_merged[df_merged['is_algorithm'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_file = \"delirium_algorithm_papers_pubmed.csv\"\n",
    "algorithm_papers.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "algorithm_papers = df_merged[df_merged['is_algorithm'] == True]\n",
    "print(f\"\\nAnalysis complete!\")\n",
    "print(f\"Found {len(algorithm_papers)} papers describing delirium algorithms\")\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Display the count by year\n",
    "year_count = algorithm_papers['Year'].value_counts().sort_index()\n",
    "print(\"\\nPapers by year:\")\n",
    "print(year_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
