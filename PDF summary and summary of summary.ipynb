{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypdf pandas your-google-generativeai python-dotenv python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "from pypdf import PdfReader\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "from docx import Document\n",
    "from docx.shared import Pt, Inches, RGBColor\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "BASE_DIR = \"your-base-dir\"\n",
    "LLM = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions dictionary with main questions and their subquestions\n",
    "DETAILED_QUESTIONS = {\n",
    "    \"What were the features used in the AI model for delirium prediction?\": [],  # Empty list for no subquestions\n",
    "    \"What was the outcome that the model tried to predict?\": [],\n",
    "    \"Which population did they study?\": [],\n",
    "    \"What is the specific purpose and context of the AI model in delirium prediction?\": [\n",
    "        \"Why was the model built?\",\n",
    "        \"Was there a specific gap in the literature that it aimed to address?\",\n",
    "        \"Does the model focus on prevalent vs. incident delirium?\",\n",
    "        \"What is the prediction window?\",\n",
    "        \"What type of ICU population is targeted?\"\n",
    "    ],\n",
    "    \"How was the model developed, and what data were used for training?\": [\n",
    "        \"What data source was used for training the model?\",\n",
    "        \"What is the distribution of the data?\",\n",
    "        \"Is the data representative of the target population?\",\n",
    "        \"What were the steps or methods used to define and select the features?\",\n",
    "        \"How were missing data and outliers assessed and managed?\",\n",
    "        \"What was the gold standard for delirium?\",\n",
    "        \"What type of ML models were tested?\",\n",
    "        \"How was hyperparameter tuning performed?\",\n",
    "        \"Was cross-validation done? What type and how many fold?\"\n",
    "    ],\n",
    "    \"Has the model been externally validated, and how does it perform in different clinical settings?\": [\n",
    "        \"Is the model externally validated?\",\n",
    "        \"What are the performance metrics?\",\n",
    "        \"What are the subgroup analysis performance metrics?\",\n",
    "        \"Are fairness metrics reported?\",\n",
    "        \"Was clinical utility tested?\"\n",
    "    ],\n",
    "    \"How interpretable are the model's outputs, and can clinicians understand the reasoning behind predictions?\": [\n",
    "        \"Have they looked at results that are wrong and tried to understand the reasoning behind the mistakes?\",\n",
    "        \"Report SHAP values or other feature ranking\"\n",
    "    ],\n",
    "    \"Are there any ethical, legal, or social concerns related to the use of the model?\": [\n",
    "        \"Has the paper discussed any of these aspects?\",\n",
    "        \"If so, which aspect and how the paper tried to address it?\"\n",
    "    ],\n",
    "    \"What training and support will be provided to clinicians to effectively use and interpret the model's predictions?\": [\n",
    "        \"Has the paper discussed training and support?\",\n",
    "        \"If so, what steps will be taken to allow the clinician to use the model and understand the model's interpretation output?\"\n",
    "    ],\n",
    "    \"How does the model integrate into existing clinical workflows and complement current practices?\": [\n",
    "        \"Do the authors describe the role of the model in clinical practice?\",\n",
    "        \"Are there steps on how the model should be used in a clinical setting? If yes, what are the steps?\"\n",
    "    ],\n",
    "    \"Has the use of the model been shown to improve patient care and outcomes in prospective studies?\": [\n",
    "        \"Has the paper reported any prospective studies on patient outcomes?\",\n",
    "        \"If so, what were the key findings regarding patient care improvement?\"\n",
    "    ],\n",
    "    \"What are the potential risks or harms associated with implementing the model in clinical practice?\": [\n",
    "        \"Has a risk assessment been done?\",\n",
    "        \"If so, what are the identified potential risks and harm?\"\n",
    "    ],\n",
    "    \"How will the model be maintained and updated over time to ensure continued accuracy and relevance?\": [\n",
    "        \"Has the life cycle of the model been discussed?\",\n",
    "        \"Are there specific plans for model updates and maintenance?\"\n",
    "    ],\n",
    "    \"What measures are in place to monitor the model's performance?\": [\n",
    "        \"Are there monitoring systems after implementation suggested in the paper? If so, what are they?\",\n",
    "        \"How frequently is the model's performance evaluated?\"\n",
    "    ],\n",
    "    \"How does the model compare to existing clinical methods for delirium prediction?\": [\n",
    "        \"Was model performance in clinical practice compared with routine clinical practice?\",\n",
    "        \"Was the Cost:Benefit ratio mentioned? If, so what was it, clinical as well as technical?\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path: str) -> Optional[str]:\n",
    "    \"\"\"Extract text from a PDF file\"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF {pdf_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_genai(api_key: str):\n",
    "    \"\"\"Set up the Google Generative AI model\"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        return genai.GenerativeModel('gemini-1.5-pro', \n",
    "                                   generation_config=genai.GenerationConfig(\n",
    "                                       temperature=0,\n",
    "                                       top_p=1,\n",
    "                                       top_k=1,\n",
    "                                       max_output_tokens=2048))\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up GenAI: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text: str, question: str, llm) -> str:\n",
    "    \"\"\"Analyze text with a specific question using GenAI\"\"\"\n",
    "    prompt = f\"\"\"Analyze this research paper and answer the following question:\n",
    "    Question: {question}\n",
    "    \n",
    "    Paper text:\n",
    "    {text}\n",
    "    \n",
    "    Provide a concise but detailed answer. If the information is not found, say \"Not mentioned in the paper.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing text: {e}\")\n",
    "        return \"Error in analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_single_paper(pdf_path: str, llm) -> Dict:\n",
    "    \"\"\"Analyze a single paper and return all results\"\"\"\n",
    "    # Extract text from PDF\n",
    "    text = process_pdf(pdf_path)\n",
    "    if text is None:\n",
    "        return None\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Extract title\n",
    "    title_prompt = \"What is the title of this research paper? Return only the title.\"\n",
    "    results['title'] = analyze_text(text, title_prompt, llm)\n",
    "    \n",
    "    # Analyze main questions\n",
    "    for main_question in DETAILED_QUESTIONS:\n",
    "        column_name = f\"Main__{main_question[:50]}\"  # Truncate long questions\n",
    "        results[column_name] = analyze_text(text, main_question, llm)\n",
    "        \n",
    "        # Analyze subquestions\n",
    "        for subq in DETAILED_QUESTIONS[main_question]:\n",
    "            column_name = f\"Sub__{main_question[:30]}__{subq[:30]}\"\n",
    "            results[column_name] = analyze_text(text, subq, llm)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_dataframe() -> pd.DataFrame:\n",
    "    \"\"\"Create DataFrame from PDF analysis without saving\"\"\"\n",
    "    try:\n",
    "        # Setup paths\n",
    "        pdf_directory = os.path.join(BASE_DIR, \"algorithm pdfs\")\n",
    "        \n",
    "        # Get list of PDF files\n",
    "        pdf_files = [f for f in os.listdir(pdf_directory) if f.endswith('.pdf')]\n",
    "        if not pdf_files:\n",
    "            raise FileNotFoundError(\"No PDF files found in directory\")\n",
    "        \n",
    "        print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "        \n",
    "        # Process all PDFs\n",
    "        results = []\n",
    "        for i, pdf_file in enumerate(pdf_files, 1):\n",
    "            print(f\"Processing file {i}/{len(pdf_files)}: {pdf_file}\")\n",
    "            pdf_path = os.path.join(pdf_directory, pdf_file)\n",
    "            paper_results = analyze_single_paper(pdf_path, LLM)\n",
    "            if paper_results:\n",
    "                paper_results['File'] = pdf_file\n",
    "                results.append(paper_results)\n",
    "            else:\n",
    "                print(f\"Warning: Could not process {pdf_file}\")\n",
    "        \n",
    "        if not results:\n",
    "            raise ValueError(\"No results were generated from any PDFs\")\n",
    "        \n",
    "        # Create and return DataFrame\n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment() -> str:\n",
    "    \"\"\"Setup environment and return API key\"\"\"\n",
    "    env_path = os.path.join(BASE_DIR, 'google_api_key.env')\n",
    "    \n",
    "    if not os.path.exists(env_path):\n",
    "        raise FileNotFoundError(f\"Environment file not found at: {env_path}\")\n",
    "    \n",
    "    load_dotenv(env_path)\n",
    "    api_key = os.getenv('GOOGLE_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY not found in google_api_key.env file\")\n",
    "    \n",
    "    return api_key\n",
    "\n",
    "# Ensure to set your API keys and other environment variables in your_env_file.env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> pd.DataFrame:\n",
    "    \"\"\"Main function to run the analysis\"\"\"\n",
    "    global LLM\n",
    "    \n",
    "    try:\n",
    "        # Setup environment and API key\n",
    "        print(\"Setting up environment...\")\n",
    "        api_key = setup_environment()\n",
    "        print(\"Using API key from google_api_key.env\")\n",
    "        \n",
    "        # Setup GenAI model\n",
    "        print(\"Initializing GenAI model...\")\n",
    "        LLM = setup_genai(api_key)\n",
    "        \n",
    "        # Create the analysis DataFrame\n",
    "        print(\"Starting analysis...\")\n",
    "        df = create_analysis_dataframe()\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nAnalysis completed successfully\")\n",
    "        print(f\"DataFrame shape: {df.shape}\")\n",
    "        print(\"First few columns:\", list(df.columns)[:5])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File error: {e}\")\n",
    "        print(\"Please ensure all required files are present\")\n",
    "        sys.exit(1)\n",
    "    except ValueError as e:\n",
    "        print(f\"Configuration error: {e}\")\n",
    "        print(\"Please check your configuration files\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        print(\"Please check the logs for more details\")\n",
    "        sys.exit(1)\n",
    "# Ensure to set your API keys and other environment variables in your_env_file.env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Setup environment and API key\n",
    "        env_path = os.path.join(BASE_DIR, 'google_api_key.env')\n",
    "        \n",
    "        if os.path.exists(env_path):\n",
    "            load_dotenv(env_path)\n",
    "            api_key = os.getenv('GOOGLE_API_KEY')\n",
    "            if api_key:\n",
    "                print(\"Using API key from google_api_key.env\")\n",
    "                # Set up the global LLM\n",
    "                LLM = setup_genai(api_key)\n",
    "            else:\n",
    "                print(\"GOOGLE_API_KEY not found in google_api_key.env file\")\n",
    "                print(\"Please create google_api_key.env file with your API key\")\n",
    "                sys.exit(1)\n",
    "        else:\n",
    "            print(f\"Environment file not found at: {env_path}\")\n",
    "            print(\"Please create google_api_key.env file with your API key\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        # Create the analysis DataFrame\n",
    "        df = create_analysis_dataframe()\n",
    "        \n",
    "        print(\"Analysis completed successfully\")\n",
    "        print(f\"DataFrame shape: {df.shape}\")\n",
    "        print(\"\\nFirst few columns:\", list(df.columns)[:5])\n",
    "        \n",
    "        # Keep the DataFrame in memory for further inspection/processing\n",
    "        # You can now examine df or save it using a separate script\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in setup: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_styles(doc: Document):\n",
    "    \"\"\"Create custom styles for the document\"\"\"\n",
    "    # Title style\n",
    "    title_style = doc.styles.add_style('StudyTitle', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    title_style.font.size = Pt(16)\n",
    "    title_style.font.bold = True\n",
    "    title_style.font.color.rgb = RGBColor(0, 0, 139)  # Dark blue\n",
    "    title_style.paragraph_format.space_before = Pt(24)\n",
    "    title_style.paragraph_format.space_after = Pt(12)\n",
    "    \n",
    "    # Main question style\n",
    "    main_q_style = doc.styles.add_style('MainQuestion', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    main_q_style.font.size = Pt(12)\n",
    "    main_q_style.font.bold = True\n",
    "    main_q_style.paragraph_format.space_before = Pt(12)\n",
    "    main_q_style.paragraph_format.space_after = Pt(6)\n",
    "    \n",
    "    # Sub question style\n",
    "    sub_q_style = doc.styles.add_style('SubQuestion', WD_STYLE_TYPE.PARAGRAPH)\n",
    "    sub_q_style.font.size = Pt(11)\n",
    "    sub_q_style.font.italic = True\n",
    "    sub_q_style.paragraph_format.left_indent = Inches(0.25)\n",
    "    sub_q_style.paragraph_format.space_before = Pt(6)\n",
    "    sub_q_style.paragraph_format.space_after = Pt(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question_text(col_name: str) -> str:\n",
    "    \"\"\"Format column names back into readable questions\"\"\"\n",
    "    if col_name.startswith('Main__'):\n",
    "        question = col_name.replace('Main__', '')\n",
    "    elif col_name.startswith('Sub__'):\n",
    "        question = col_name.split('__')[-1]\n",
    "    else:\n",
    "        return col_name\n",
    "    \n",
    "    question = question.replace('_', ' ')\n",
    "    if not question.endswith('?'):\n",
    "        question += '?'\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simply call this with your existing DataFrame\n",
    "output_path = \"delirium_analysis_report.docx\"\n",
    "doc = Document()\n",
    "create_custom_styles(doc)\n",
    "doc.add_heading('Delirium Prediction Models Analysis', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each paper\n",
    "for idx, row in df.iterrows():\n",
    "    # Add study title\n",
    "    title = row['title']\n",
    "    doc.add_paragraph(title, style='StudyTitle')\n",
    "    \n",
    "    # Add file name in smaller text\n",
    "    file_info = doc.add_paragraph(f\"Source file: {row['File']}\")\n",
    "    file_info.runs[0].font.size = Pt(8)\n",
    "    file_info.runs[0].font.italic = True\n",
    "    \n",
    "    # Process main questions\n",
    "    for col in df.columns:\n",
    "        if col.startswith('Main__'):\n",
    "            # Add main question\n",
    "            question_text = format_question_text(col)\n",
    "            main_q = doc.add_paragraph(question_text, style='MainQuestion')\n",
    "            \n",
    "            # Add main answer\n",
    "            doc.add_paragraph(row[col])\n",
    "            \n",
    "            # Find and add related subquestions\n",
    "            main_prefix = col.split('__')[1][:30]\n",
    "            related_subqs = [c for c in df.columns if c.startswith(f'Sub__{main_prefix}')]\n",
    "            \n",
    "            for sub_col in related_subqs:\n",
    "                if pd.notna(row[sub_col]) and row[sub_col] != \"Not mentioned in the paper\":\n",
    "                    # Add subquestion and its answer\n",
    "                    sub_text = format_question_text(sub_col)\n",
    "                    sub_p = doc.add_paragraph(style='SubQuestion')\n",
    "                    sub_p.add_run(f\"{sub_text}\\n\").bold = True\n",
    "                    sub_p.add_run(row[sub_col])\n",
    "    \n",
    "    # Add page break between papers\n",
    "    doc.add_page_break()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the document\n",
    "try:\n",
    "    doc.save(output_path)\n",
    "    print(f\"Successfully saved analysis to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving document: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question(col_name: str) -> str:\n",
    "    \"\"\"Convert column names back to readable questions\"\"\"\n",
    "    if col_name.startswith('Main__'):\n",
    "        question = col_name.replace('Main__', '')\n",
    "    elif col_name.startswith('Sub__'):\n",
    "        question = col_name.split('__')[-1]\n",
    "    else:\n",
    "        return col_name\n",
    "    \n",
    "    question = question.replace('_', ' ')\n",
    "    if not question.endswith('?'):\n",
    "        question += '?'\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_question_with_genai(responses: List[str], question: str, model) -> str:\n",
    "    \"\"\"Use GenAI to analyze responses for a specific question\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are analyzing multiple research papers about delirium prediction models. \n",
    "    Analyze these {len(responses)} different responses to the question: \"{question}\"\n",
    "    \n",
    "    Responses:\n",
    "    {'\\n'.join([f'Paper {i+1}: {resp}' for i, resp in enumerate(responses)])}\n",
    "    \n",
    "    Provide a comprehensive summary that includes:\n",
    "    1. General trends and common approaches across papers\n",
    "    2. Unique or innovative approaches mentioned\n",
    "    3. Gaps or limitations commonly noted\n",
    "    4. Important technical details (if relevant)\n",
    "    5. Clinical implications\n",
    "    \n",
    "    Format the response in clear paragraphs. Focus on what's most relevant for a medical journal manuscript.\n",
    "    Be specific about numbers (e.g., \"3 out of 5 studies used...\") when possible.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error generating summary: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comprehensive_summary(df: pd.DataFrame, model) -> str:\n",
    "    \"\"\"Generate a comprehensive summary of all questions and responses\"\"\"\n",
    "    summary_text = \"# Comprehensive Analysis of Delirium Prediction Models\\n\\n\"\n",
    "    \n",
    "    # Process main questions\n",
    "    main_questions = [col for col in df.columns if col.startswith('Main__')]\n",
    "    \n",
    "    for main_q in main_questions:\n",
    "        question = format_question(main_q)\n",
    "        responses = df[main_q].dropna().tolist()\n",
    "        \n",
    "        if responses:\n",
    "            summary_text += f\"## {question}\\n\\n\"\n",
    "            summary = analyze_question_with_genai(responses, question, model)\n",
    "            summary_text += f\"{summary}\\n\\n\"\n",
    "            \n",
    "            # Find and process related subquestions\n",
    "            main_prefix = main_q.split('__')[1][:30]\n",
    "            related_subqs = [col for col in df.columns \n",
    "                           if col.startswith(f'Sub__{main_prefix}')]\n",
    "            \n",
    "            if related_subqs:\n",
    "                summary_text += \"### Detailed Analysis\\n\\n\"\n",
    "                for sub_q in related_subqs:\n",
    "                    sub_question = format_question(sub_q)\n",
    "                    sub_responses = df[sub_q].dropna().tolist()\n",
    "                    \n",
    "                    if sub_responses:\n",
    "                        summary_text += f\"#### {sub_question}\\n\\n\"\n",
    "                        sub_summary = analyze_question_with_genai(sub_responses, \n",
    "                                                               sub_question, \n",
    "                                                               model)\n",
    "                        summary_text += f\"{sub_summary}\\n\\n\"\n",
    "            \n",
    "            summary_text += \"---\\n\\n\"\n",
    "    \n",
    "    return summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_summary(summary_text: str, base_output_path: str):\n",
    "    \"\"\"Save the summary in multiple formats\"\"\"\n",
    "    # Save as markdown\n",
    "    md_path = f\"{base_output_path}.md\"\n",
    "    with open(md_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(summary_text)\n",
    "    print(f\"Summary saved as markdown: {md_path}\")\n",
    "    \n",
    "    # Save as plain text\n",
    "    txt_path = f\"{base_output_path}.txt\"\n",
    "    with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(summary_text)\n",
    "    print(f\"Summary saved as text: {txt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Load environment variables\n",
    "        load_dotenv('google_api_key.env')\n",
    "        api_key = os.getenv('GOOGLE_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "        \n",
    "        # Setup GenAI with API key\n",
    "        print(\"Setting up Google's Generative AI...\")\n",
    "        model = setup_genai(api_key)\n",
    "        \n",
    "        # Generate comprehensive summary using the existing DataFrame (df)\n",
    "        print(\"\\nGenerating comprehensive summary...\")\n",
    "        summary_text = generate_comprehensive_summary(df, model)\n",
    "        \n",
    "        # Save the summary\n",
    "        print(\"\\nSaving summary...\")\n",
    "        save_summary(summary_text, \"delirium_models_analysis\")\n",
    "        \n",
    "        # Print preview\n",
    "        print(\"\\nFirst few lines of the summary:\")\n",
    "        print(\"\\n\".join(summary_text.split(\"\\n\")[:10]))\n",
    "        \n",
    "        print(\"\\nSummary generation complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in summary generation: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
